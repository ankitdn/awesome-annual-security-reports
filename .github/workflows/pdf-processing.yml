name: PDF Processing Workflow

on:
  push:
    branches:
      - development
    paths:
      - 'Annual Security Reports/**/*.pdf'

jobs:
  process-pdf:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # To get the previous commit for comparison
      
      - name: Find changed PDF files
        id: changed-pdfs
        run: |
          # Get list of added or modified PDF files
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD | grep -E "Annual Security Reports/.+\.pdf$" || echo "")
          if [ -z "$CHANGED_FILES" ]; then
            echo "No PDF files were changed"
            echo "pdf_files=" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Convert to JSON array format
          JSON_ARRAY=$(echo "$CHANGED_FILES" | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "pdf_files=$JSON_ARRAY" >> $GITHUB_OUTPUT
          echo "Found changed PDFs: $JSON_ARRAY"
      
      - name: Set up Python
        if: ${{ steps.changed-pdfs.outputs.pdf_files != '[]' && steps.changed-pdfs.outputs.pdf_files != '' }}
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        if: ${{ steps.changed-pdfs.outputs.pdf_files != '[]' && steps.changed-pdfs.outputs.pdf_files != '' }}
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Scan PDFs with Hybrid Analysis
        if: ${{ steps.changed-pdfs.outputs.pdf_files != '[]' && steps.changed-pdfs.outputs.pdf_files != '' }}
        id: hybrid-analysis
        env:
          HYBRID_ANALYSIS_API_KEY: ${{ secrets.HYBRID_ANALYSIS_API_KEY }}
        run: |
          python - <<EOF
          import os
          import json
          import requests
          import time
          import hashlib
          
          # Parse the JSON array of PDF files
          pdf_files = json.loads('${{ steps.changed-pdfs.outputs.pdf_files }}')
          results = {}
          
          api_key = os.environ['HYBRID_ANALYSIS_API_KEY']
          api_url = "https://www.hybrid-analysis.com/api/v2"
          
          headers = {
              "api-key": api_key,
              "User-Agent": "Falcon Sandbox"
          }
          
          for pdf_file in pdf_files:
              print(f"Processing file: {pdf_file}")
              
              # Calculate SHA256 of the file
              with open(pdf_file, 'rb') as f:
                  file_content = f.read()
                  sha256 = hashlib.sha256(file_content).hexdigest()
                  
              # Check if file has been analyzed before
              search_url = f"{api_url}/search/hash"
              search_response = requests.post(
                  search_url,
                  headers=headers,
                  data={"hash": sha256}
              )
              
              if search_response.status_code == 200 and search_response.json():
                  # File has been analyzed before
                  result = search_response.json()[0]
                  scan_id = result.get("job_id")
                  threat_score = result.get("threat_score", 0)
                  verdict = result.get("verdict", "unknown")
                  report_url = f"https://www.hybrid-analysis.com/sample/{sha256}"
              else:
                  # Submit file for analysis
                  files = {'file': (os.path.basename(pdf_file), open(pdf_file, 'rb'))}
                  submit_url = f"{api_url}/submit/file"
                  
                  submit_response = requests.post(
                      submit_url,
                      headers=headers,
                      files=files,
                      data={"environment_id": 120}  # Windows 10 64-bit environment
                  )
                  
                  if submit_response.status_code != 200:
                      print(f"Error submitting file: {submit_response.text}")
                      results[pdf_file] = {
                          "error": f"Submission failed: {submit_response.text}",
                          "clean": False
                      }
                      continue
                      
                  submission = submit_response.json()
                  scan_id = submission.get("job_id")
                  report_url = f"https://www.hybrid-analysis.com/sample/{sha256}"
                  
                  # Wait for analysis to complete (with timeout)
                  max_wait_time = 300  # 5 minutes
                  wait_interval = 10  # seconds
                  elapsed_time = 0
                  
                  while elapsed_time < max_wait_time:
                      time.sleep(wait_interval)
                      elapsed_time += wait_interval
                      
                      # Check status
                      report_url = f"{api_url}/report/{scan_id}/summary"
                      report_response = requests.get(
                          report_url,
                          headers=headers
                      )
                      
                      if report_response.status_code == 200:
                          report = report_response.json()
                          state = report.get("state", "")
                          
                          if state == "SUCCESS":
                              threat_score = report.get("threat_score", 0)
                              verdict = report.get("verdict", "unknown")
                              break
                      
                      print(f"Waiting for analysis to complete... ({elapsed_time} seconds elapsed)")
                  
                  if elapsed_time >= max_wait_time:
                      print(f"Analysis timed out for {pdf_file}")
                      # We'll still proceed but mark it as potentially not clean
                      threat_score = 100
                      verdict = "timeout"
              
              # Determine if file is clean (threat score < 10 is typically considered safe)
              is_clean = threat_score < 10 and verdict.lower() in ["no verdict", "no specific threat", "clean", "unknown"]
              
              # Store results
              results[pdf_file] = {
                  "scan_id": scan_id,
                  "report_url": report_url,
                  "threat_score": threat_score,
                  "verdict": verdict,
                  "clean": is_clean
              }
              
              print(f"Analysis results for {pdf_file}:")
              print(f"  Report URL: {report_url}")
              print(f"  Threat Score: {threat_score}")
              print(f"  Verdict: {verdict}")
              print(f"  Clean: {is_clean}")
          
          # Write results to file for artifacts
          with open('scan_results.json', 'w') as f:
              json.dump(results, f, indent=2)
          
          # Set output for next steps
          clean_files = []
          for pdf_file, result in results.items():
              if result["clean"]:
                  clean_files.append(pdf_file)
          
          clean_files_json = json.dumps(clean_files)
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"clean_files={clean_files_json}\n")
          EOF
      
      - name: Upload scan results as artifact
        if: ${{ steps.changed-pdfs.outputs.pdf_files != '[]' && steps.changed-pdfs.outputs.pdf_files != '' }}
        uses: actions/upload-artifact@v3
        with:
          name: hybrid-analysis-results
          path: scan_results.json
      
      - name: Install Google Cloud SDK
        if: ${{ steps.hybrid-analysis.outputs.clean_files != '[]' && steps.hybrid-analysis.outputs.clean_files != '' }}
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true
      
      - name: Install PDF extraction tools
        if: ${{ steps.hybrid-analysis.outputs.clean_files != '[]' && steps.hybrid-analysis.outputs.clean_files != '' }}
        run: |
          sudo apt-get update
          sudo apt-get install -y poppler-utils
          pip install PyPDF2
      
      - name: Process clean PDFs with Gemini AI
        if: ${{ steps.hybrid-analysis.outputs.clean_files != '[]' && steps.hybrid-analysis.outputs.clean_files != '' }}
        id: gemini-processing
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python - <<EOF
          import os
          import json
          import requests
          import re
          import subprocess
          import PyPDF2
          import base64
          from io import BytesIO
          
          # Parse the JSON array of clean PDF files
          clean_files = json.loads('${{ steps.hybrid-analysis.outputs.clean_files }}')
          
          # Get the AI prompt content
          with open('AI_PROMPT_MARKDOWN_CONVERT.md', 'r') as f:
              prompt_content = f.read()
          
          gemini_api_key = os.environ['GEMINI_API_KEY']
          gemini_api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
          
          for pdf_file in clean_files:
              print(f"Processing clean file with Gemini: {pdf_file}")
              
              # Extract filename and path components
              filename = os.path.basename(pdf_file)
              base_name = os.path.splitext(filename)[0]
              year_match = re.search(r'/(\d{4})/', pdf_file)
              year = year_match.group(1) if year_match else "unknown_year"
              
              # Construct the target markdown path
              md_dir = f"Markdown Conversions/{year}"
              md_path = f"{md_dir}/{base_name}.md"
              
              # Ensure target directory exists
              os.makedirs(md_dir, exist_ok=True)
              
              # Try multiple PDF extraction methods
              pdf_texts = []
              
              # Method 1: Use pdftotext (from poppler-utils)
              try:
                  result = subprocess.run(
                      ['pdftotext', pdf_file, '-'],
                      capture_output=True, 
                      text=True, 
                      check=True
                  )
                  if result.stdout.strip():
                      pdf_texts.append(f"[pdftotext extraction]\n{result.stdout}")
              except (subprocess.CalledProcessError, FileNotFoundError) as e:
                  print(f"pdftotext extraction failed: {e}")
              
              # Method 2: Use PyPDF2
              try:
                  with open(pdf_file, 'rb') as f:
                      pdf_reader = PyPDF2.PdfReader(f)
                      text = ""
                      for page_num in range(len(pdf_reader.pages)):
                          text += pdf_reader.pages[page_num].extract_text() + "\n\n"
                      if text.strip():
                          pdf_texts.append(f"[PyPDF2 extraction]\n{text}")
              except Exception as e:
                  print(f"PyPDF2 extraction failed: {e}")
              
              # If we have any extracted text, use it
              pdf_text = "\n\n".join(pdf_texts) if pdf_texts else f"Failed to extract text from {filename}."
              
              # Encode the PDF for multimodal input to Gemini if no text extraction worked
              pdf_data = None
              if not pdf_texts:
                  try:
                      with open(pdf_file, 'rb') as f:
                          pdf_data = base64.b64encode(f.read()).decode('utf-8')
                  except Exception as e:
                      print(f"Failed to read PDF file for base64 encoding: {e}")
              
              # Construct the prompt for Gemini
              headers = {
                  "Content-Type": "application/json",
                  "x-goog-api-key": gemini_api_key
              }
              
              # Different payload based on whether we have extracted text or need to use the PDF directly
              if pdf_texts:
                  # Text-based prompt
                  full_prompt = f"{prompt_content}\n\nPDF Content:\n{pdf_text}"
                  payload = {
                      "contents": [{
                          "parts": [{
                              "text": full_prompt
                          }]
                      }],
                      "generationConfig": {
                          "temperature": 0.2,
                          "topP": 0.8,
                          "maxOutputTokens": 8192
                      }
                  }
              elif pdf_data:
                  # Multimodal prompt with PDF file
                  payload = {
                      "contents": [{
                          "parts": [
                              {
                                  "text": prompt_content
                              },
                              {
                                  "inline_data": {
                                      "mime_type": "application/pdf",
                                      "data": pdf_data
                                  }
                              }
                          ]
                      }],
                      "generationConfig": {
                          "temperature": 0.2,
                          "topP": 0.8,
                          "maxOutputTokens": 8192
                      }
                  }
              else:
                  # Fallback if we couldn't extract text or read the PDF
                  print(f"Skipping {pdf_file} as we couldn't extract text or read the PDF file")
                  continue
              
              response = requests.post(
                  gemini_api_url,
                  headers=headers,
                  json=payload
              )
              
              try:
                  if response.status_code == 200:
                      result = response.json()
                      # Extract markdown content from Gemini response
                      markdown_content = ""
                      try:
                          for part in result["candidates"][0]["content"]["parts"]:
                              if "text" in part:
                                  markdown_content += part["text"]
                      except (KeyError, IndexError) as e:
                          print(f"Error parsing Gemini response: {e}")
                          continue
                      
                      # Validate the markdown content
                      if len(markdown_content) < 100:
                          print(f"Warning: Generated markdown for {filename} seems too short. Skipping.")
                          continue
                      
                      # Write the markdown file
                      with open(md_path, 'w') as f:
                          f.write(markdown_content)
                      
                      print(f"Created markdown file: {md_path}")
                      
                      # Get extraction method used
                      extraction_method = "multimodal PDF input"
                      if pdf_texts:
                          if "[pdftotext extraction]" in pdf_texts[0]:
                              extraction_method = "pdftotext"
                          elif "[PyPDF2 extraction]" in pdf_texts[0]:
                              extraction_method = "PyPDF2"
                      
                      # Create detailed commit message
                      commit_message = f"""
Convert {filename} to markdown

Processing details:
- AI Prompt: V1.0
- Model: Gemini 1.5 Flash
- Extraction method: {extraction_method}
- Processed by GitHub Action
                      """.strip()
                      
                      # Use subprocess to better handle errors
                      subprocess.run(['git', 'config', '--local', 'user.email', 'action@github.com'], check=True)
                      subprocess.run(['git', 'config', '--local', 'user.name', 'GitHub Action'], check=True)
                      subprocess.run(['git', 'add', md_path], check=True)
                      subprocess.run(['git', 'commit', '-m', commit_message], check=True)
                      subprocess.run(['git', 'push'], check=True)
                  else:
                      print(f"Error calling Gemini API (Status {response.status_code}): {response.text}")
              except Exception as e:
                  print(f"Unexpected error processing {filename}: {e}")
          EOF
