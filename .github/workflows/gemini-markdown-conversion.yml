name: Gemini Markdown Conversion

on:
  repository_dispatch:
    types: [start-gemini-conversion]

jobs:
  convert-to-markdown:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install requests google-generativeai PyPDF2
      
      - name: Read AI prompt
        id: read-prompt
        run: |
          PROMPT_CONTENT=$(cat AI_PROMPT_MARKDOWN_CONVERT.md)
          PROMPT_CONTENT="${PROMPT_CONTENT//'%'/'%25'}"
          PROMPT_CONTENT="${PROMPT_CONTENT//$'\n'/'%0A'}"
          PROMPT_CONTENT="${PROMPT_CONTENT//$'\r'/'%0D'}"
          echo "prompt=$PROMPT_CONTENT" >> $GITHUB_OUTPUT
      
      - name: Convert PDF to Markdown with Gemini
        id: gemini-convert
        run: |
          cat > convert_pdf.py << 'EOF'
          import sys
          import os
          import time
          import json
          import base64
          import PyPDF2
          import requests
          import google.generativeai as genai

          # Get inputs
          pdf_path = os.environ['PDF_PATH']
          pdf_year = os.environ['PDF_YEAR']
          pdf_name = os.environ['PDF_NAME']
          prompt_text = os.environ['PROMPT_TEXT']
          api_key = os.environ['GEMINI_API_KEY']

          # Configure Gemini API
          genai.configure(api_key=api_key)

          def extract_text_from_pdf(pdf_path):
              with open(pdf_path, 'rb') as file:
                  pdf_reader = PyPDF2.PdfReader(file)
                  text = ""
                  for page_num in range(len(pdf_reader.pages)):
                      text += pdf_reader.pages[page_num].extract_text() + "\n\n"
              return text

          def try_gemini_model(model_name, pdf_text, prompt):
              try:
                  print(f"Trying model: {model_name}")
                  model = genai.GenerativeModel(model_name)
                  
                  # Prepare the complete prompt with the PDF content
                  complete_prompt = f"{prompt}\n\nHere is the PDF content to convert:\n\n{pdf_text}"
                  
                  # Generate content
                  response = model.generate_content(complete_prompt, 
                                                   generation_config={"temperature": 0.2, 
                                                                     "max_output_tokens": 8192})
                  
                  markdown_content = response.text
                  model_used = model_name
                  return markdown_content, model_used, True
              
              except Exception as e:
                  print(f"Error with {model_name}: {str(e)}")
                  return None, model_name, False

          # Main conversion process
          try:
              # Extract text from PDF
              print(f"Extracting text from {pdf_path}")
              pdf_text = extract_text_from_pdf(pdf_path)
              
              # Find the best model to use
              models_to_try = ["gemini-2.0-flash", "gemini-2.0-flash-lite"]
              
              markdown_content = None
              model_used = None
              success = False
              
              for model in models_to_try:
                  markdown_content, model_used, success = try_gemini_model(model, pdf_text, prompt_text)
                  if success:
                      break
              
              if not success:
                  print("All models failed to process the PDF")
                  sys.exit(1)
              
              # Ensure the output directory exists
              output_dir = f"Markdown Conversions/{pdf_year}"
              os.makedirs(output_dir, exist_ok=True)
              
              # Create markdown file
              output_file = f"{output_dir}/{pdf_name}.md"
              with open(output_file, "w") as f:
                  f.write(markdown_content)
              
              print(f"Successfully converted PDF to Markdown using {model_used}")
              print(f"Output file: {output_file}")
              
              # Output for GitHub Actions
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"markdown_path={output_file}\n")
                  f.write(f"model_used={model_used}\n")
              
          except Exception as e:
              print(f"Error: {str(e)}")
              sys.exit(1)
          EOF

          python convert_pdf.py
        env:
          PDF_PATH: ${{ github.event.client_payload.pdf_path }}
          PDF_YEAR: ${{ github.event.client_payload.pdf_year }}
          PDF_NAME: ${{ github.event.client_payload.pdf_name }}
          PROMPT_TEXT: ${{ steps.read-prompt.outputs.prompt }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GITHUB_OUTPUT: $GITHUB_OUTPUT
      
      - name: Commit markdown file
        run: |
          MARKDOWN_PATH="${{ steps.gemini-convert.outputs.markdown_path }}"
          MODEL_USED="${{ steps.gemini-convert.outputs.model_used }}"
          SCAN_URL="${{ github.event.client_payload.scan_url }}"
          
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          git add "$MARKDOWN_PATH"
          git commit -m "Convert PDF to Markdown: ${MARKDOWN_PATH}
          
          Processing details:
          - AI Prompt: V1.0
          - Model: ${MODEL_USED}
          - Security scan: ${SCAN_URL}"
          
          git push
