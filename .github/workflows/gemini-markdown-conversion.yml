name: Gemini Markdown Conversion

on:
  workflow_dispatch:
    inputs:
      pdf_path:
        description: 'Path to the PDF file'
        required: true
      target_markdown_path:
        description: 'Target path for the markdown file'
        required: true
      scan_url:
        description: 'Hybrid-Analysis scan URL'
        required: true

jobs:
  convert-to-markdown:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests PyPDF2
      
      - name: Ensure directory exists
        run: |
          mkdir -p "$(dirname "${{ inputs.target_markdown_path }}")"
      
      - name: Convert PDF to text
        id: extract_text
        run: |
          python -c "
          import PyPDF2
          import json
          
          # Extract text from PDF
          pdf_path = '${{ inputs.pdf_path }}'
          text = ''
          
          with open(pdf_path, 'rb') as file:
              pdf_reader = PyPDF2.PdfReader(file)
              for page_num in range(len(pdf_reader.pages)):
                  text += pdf_reader.pages[page_num].extract_text() + '\n\n'
          
          # Save text to file for processing
          with open('pdf_content.txt', 'w', encoding='utf-8') as f:
              f.write(text)
          
          # Save some metadata
          pdf_metadata = {
              'filename': pdf_path.split('/')[-1],
              'pages': len(pdf_reader.pages),
              'title': pdf_reader.metadata.title if pdf_reader.metadata.title else 'Unknown'
          }
          
          with open('pdf_metadata.json', 'w') as f:
              json.dump(pdf_metadata, f)
          "
      
      - name: Read AI prompt template
        id: get_prompt
        run: |
          PROMPT_TEMPLATE=$(cat AI_PROMPT_MARKDOWN_CONVERT.md)
          echo "PROMPT_TEMPLATE<<EOF" >> $GITHUB_ENV
          echo "$PROMPT_TEMPLATE" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
      
      - name: Process with Gemini Flash
        id: gemini_flash
        continue-on-error: true
        run: |
          # Read the PDF content
          PDF_CONTENT=$(cat pdf_content.txt)
          
          # Create a temp file for the prompt processing
          cp AI_PROMPT_MARKDOWN_CONVERT.md prompt_template.txt
          
          # Use a more reliable method to replace the placeholder
          PDF_CONTENT_ESCAPED=$(cat pdf_content.txt | jq -Rs .)
          
          # Create the request body
          REQUEST_BODY=$(cat <<EOF
          {
            "contents": [
              {
                "parts": [
                  {
                    "text": "Convert the following PDF content to markdown format according to these instructions: $(cat AI_PROMPT_MARKDOWN_CONVERT.md | jq -Rs .)"
                  },
                  {
                    "text": "PDF Content: ${PDF_CONTENT_ESCAPED}"
                  }
                ]
              }
            ],
            "generationConfig": {
              "temperature": 0.2,
              "topK": 40,
              "topP": 0.95,
              "maxOutputTokens": 8192
            }
          }
          EOF
          )
          
          # Call Gemini API
          RESPONSE=$(curl -s -X POST "https://generativelanguage.googleapis.com/v1/models/gemini-2.0-flash:generateContent?key=${{ secrets.GEMINI_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d "$REQUEST_BODY")
          
          # Check if the response contains errors
          ERROR=$(echo "$RESPONSE" | jq -r '.error.message // empty')
          if [ -n "$ERROR" ]; then
            echo "Error from Gemini Flash: $ERROR"
            exit 1
          fi
          
          # Extract the markdown content
          MARKDOWN=$(echo "$RESPONSE" | jq -r '.candidates[0].content.parts[0].text')
          
          # Save markdown to file
          echo "$MARKDOWN" > converted_markdown.md
          
          # Set model used
          echo "model_used=gemini-2.0-flash" >> $GITHUB_OUTPUT
      
      - name: Fallback to Gemini Flash Lite
        id: gemini_flash_lite
        if: steps.gemini_flash.outcome == 'failure'
        run: |
          # Read the PDF content
          PDF_CONTENT=$(cat pdf_content.txt)
          
          # Use a more reliable method to replace the placeholder
          PDF_CONTENT_ESCAPED=$(cat pdf_content.txt | jq -Rs .)
          
          # Create the request body
          REQUEST_BODY=$(cat <<EOF
          {
            "contents": [
              {
                "parts": [
                  {
                    "text": "Convert the following PDF content to markdown format according to these instructions: $(cat AI_PROMPT_MARKDOWN_CONVERT.md | jq -Rs .)"
                  },
                  {
                    "text": "PDF Content: ${PDF_CONTENT_ESCAPED}"
                  }
                ]
              }
            ],
            "generationConfig": {
              "temperature": 0.2,
              "topK": 40,
              "topP": 0.95,
              "maxOutputTokens": 4096
            }
          }
          EOF
          )
          
          # Call Gemini API with lite model
          RESPONSE=$(curl -s -X POST "https://generativelanguage.googleapis.com/v1/models/gemini-2.0-flash-lite:generateContent?key=${{ secrets.GEMINI_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d "$REQUEST_BODY")
          
          # Check if the response contains errors
          ERROR=$(echo "$RESPONSE" | jq -r '.error.message // empty')
          if [ -n "$ERROR" ]; then
            echo "Error from Gemini Flash Lite: $ERROR"
            exit 1
          fi
          
          # Extract the markdown content
          MARKDOWN=$(echo "$RESPONSE" | jq -r '.candidates[0].content.parts[0].text')
          
          # Save markdown to file
          echo "$MARKDOWN" > converted_markdown.md
          
          # Set model used
          echo "model_used=gemini-2.0-flash-lite" >> $GITHUB_OUTPUT
      
      - name: Get model used
        id: get_model
        run: |
          if [ "${{ steps.gemini_flash.outcome }}" == "success" ]; then
            echo "model=${{ steps.gemini_flash.outputs.model_used }}" >> $GITHUB_OUTPUT
          else
            echo "model=${{ steps.gemini_flash_lite.outputs.model_used }}" >> $GITHUB_OUTPUT
          fi
      
      - name: Commit markdown file
        run: |
          # Copy the markdown to the target path
          cp converted_markdown.md "${{ inputs.target_markdown_path }}"
          
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Add, commit, and push
          git add "${{ inputs.target_markdown_path }}"
          git commit -m "Add markdown conversion for ${{ inputs.pdf_path }}
          
          Processing details:
          - AI Prompt V1.0
          - Model ${{ steps.get_model.outputs.model }}
          - Scan URL: ${{ inputs.scan_url }}"
          
          git push
